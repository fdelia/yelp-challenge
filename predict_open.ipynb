{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import os; import json; import fileinput\n",
    "#from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = time()\n",
    "fileinput.close() # sometimes fileinput is already active\n",
    "\n",
    "def load_file(filename, transformer=None, max_lines = 50000):\n",
    "    data_dir = \"yelp_dataset_challenge_round9\"\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "    data = []\n",
    "    for line in fileinput.input(filepath):\n",
    "        d = json.loads(line)\n",
    "                \n",
    "        if transformer:\n",
    "            d = transformer(d)\n",
    "\n",
    "        data.append(d)\n",
    "        if len(data) > max_lines: break\n",
    "            \n",
    "    fileinput.close()\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# These functions transform some values for later\n",
    "def transf_checkin(d):\n",
    "    d['n_time'] = len(d['time'])\n",
    "    return d\n",
    "\n",
    "def transf_review(d):\n",
    "    d['date'] = datetime.strptime(d['date'], '%Y-%m-%d')\n",
    "    d['weekday'] = d['date'].weekday()\n",
    "    return d\n",
    "\n",
    "def transf_user(d):    \n",
    "    d['n_friends'] = len(d['friends'])\n",
    "    d['n_elite'] = len(d['elite'])\n",
    "    del d['friends']\n",
    "    del d['elite']\n",
    "    #del d['compliment_writer'] # are there more than one type?\n",
    "    return d\n",
    "\n",
    "df_bus = load_file(\"yelp_academic_dataset_business.json\", None, 500000)\n",
    "df_checkin = load_file(\"yelp_academic_dataset_checkin.json\", transf_checkin)\n",
    "df_review = load_file(\"yelp_academic_dataset_review.json\", transf_review, 500000)\n",
    "df_tip = load_file(\"yelp_academic_dataset_tip.json\")\n",
    "df_user = load_file(\"yelp_academic_dataset_user.json\", transf_user)\n",
    "\n",
    "def hours_to_matrix(hours):\n",
    "    mat = np.zeros((7,), dtype=np.int8)\n",
    "    if hours is None: \n",
    "        return mat\n",
    "    day = 0\n",
    "    for h in hours:\n",
    "        length = 0\n",
    "        rr = re.findall(\"[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE]\\d+)?\", h)\n",
    "        if len(rr):\n",
    "            length = int(rr[2]) - int(rr[0])\n",
    "            if length < 0:\n",
    "                length += 24\n",
    "                \n",
    "        if h.startswith('Mon'): day = 0\n",
    "        if h.startswith('Tue'): day = 1\n",
    "        if h.startswith('Wed'): day = 2\n",
    "        if h.startswith('Thu'): day = 3\n",
    "        if h.startswith('Fri'): day = 4\n",
    "        if h.startswith('Sat'): day = 5\n",
    "        if h.startswith('Sun'): day = 6\n",
    "        mat[day] = length\n",
    "    return mat\n",
    "\n",
    "# add attributes columns\n",
    "# TODO unfinished for \"GoodForMeal\", \"Ambience\"\n",
    "def add_attribute_cols(attr):\n",
    "    s = {}\n",
    "    if attr is not None:\n",
    "        for a in attr:\n",
    "            t = a.split(':')\n",
    "            if \"True\" in t[1]:\n",
    "                s[\"attr_\" + t[0].strip()] = 1\n",
    "            else:\n",
    "                s[\"attr_\" + t[0].strip()] = 0\n",
    "            if \"RestaurantsPriceRange2\" in a:\n",
    "                s[\"attr_RestaurantsPriceRange2\"] = int(t[1])\n",
    "            if \"WiFi: free\" in a:\n",
    "                s[\"attr_WiFi\"] = 1\n",
    "            if \"BusinessParking\" in a: # improvable\n",
    "                counter = 0\n",
    "                for b in [\"'garage': True\", \"'street': True\", \"'lot': True\", \"'valet': True\"]:\n",
    "                    if b in a:\n",
    "                        counter += 1\n",
    "                s[\"n_parking\"] = counter\n",
    "    return pd.Series(s, dtype=np.int8)\n",
    "\n",
    "df_bus['opening_hours'] = df_bus['hours'].apply(hours_to_matrix)\n",
    "df_bus = df_bus.merge(df_bus['attributes'].apply(add_attribute_cols).fillna(0, downcast='infer'), left_index=True, right_index=True)\n",
    "#df_bus = df_bus.fillna(0, downcast='infer')\n",
    "\n",
    "df_review = df_review.sort_values(['business_id'])\n",
    "\n",
    "#df_user['friends']\n",
    "#df_user['elite']\n",
    "\n",
    "# Memory optimization\n",
    "# Technical stuff, contributes nothing to analysis\n",
    "for df in [df_bus, df_checkin, df_review, df_tip, df_user]:\n",
    "    conv = df.select_dtypes(include=['int']).apply(pd.to_numeric,downcast='unsigned')\n",
    "    df[conv.columns] = conv\n",
    "\n",
    "# Show memory usage\n",
    "#df_bus.info(memory_usage='deep')\n",
    "\n",
    "print('Done in {} s'.format(time() - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "reviews = df_review[df_review['date'] > datetime(2015, 1, 1)]\n",
    "#reviews = df_review\n",
    "reviews = reviews.groupby(['business_id', 'weekday'])\n",
    "\n",
    "\"\"\"\n",
    "reviews = reviews.merge(df_bus[['business_id', 'opening_hours', 'is_open']])\n",
    "reviews['hours_open'] = reviews.apply(lambda x: x['opening_hours'][x['weekday']], axis=1)    \n",
    "def is_open(hours):\n",
    "    if hours > 0: return 1\n",
    "    else: return 0\n",
    "reviews['open'] = reviews['hours_open'].apply(is_open)\n",
    "\n",
    "# Only take businesses with reviews\n",
    "reviews = reviews[(reviews['n_reviews']>0) & (reviews['is_open']==1)]\n",
    "\n",
    "sns.lmplot('n_reviews', 'hours_open', data=reviews,\n",
    "           fit_reg=False)\n",
    "plt.ylabel('hours open')\n",
    "plt.xlabel('n reviews')\n",
    "plt.show()\n",
    "\n",
    "#reviews.groupby('open').size()\n",
    "#reviews.corr()\n",
    "\"\"\"\n",
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "X = reviews[['weekday', 'n_reviews']]\n",
    "y = reviews['hours_open']\n",
    "\n",
    "print('Data prepared. Rows: {}'.format(len(X)))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=999)        \n",
    "\n",
    "# train model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, explained_variance_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.feature_extraction import TfidfVectorizer\n",
    "\n",
    "model = Pipeline([\n",
    "#    ('scaler', StandardScaler()),\n",
    "#    ('learner', LogisticRegression())\n",
    "#    ('classifier', MLPClassifier())\n",
    "    ('tfidf', TfidfVectorizer())\n",
    "    ('regressor', MLPRegressor(alpha=0.01, hidden_layer_sizes=(100, 50)))\n",
    " #   ('regressor', NuSVR())\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R^2: %1.3f\" % r2_score(y_test, y_pred))\n",
    "print(\"Explained var: {:3f}\".format(explained_variance_score(y_test, y_pred)))\n",
    "if 'classifier' in model.named_steps:\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "\"\"\"\n",
    "X_res = X_test['n_reviews']\n",
    "plt.scatter(X_res, y_test, color='black', label='actual')\n",
    "plt.scatter(X_res, y_pred, color='red', label='predicted')\n",
    "plt.xlabel('n_reviews')\n",
    "plt.legend(); plt.title('Test data')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "if False:\n",
    "    st = time()\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    print('Start cv grid search...')\n",
    "    params = {\n",
    "        'regressor__hidden_layer_sizes': [(200,), (100,), (100, 100), (100, 50)],\n",
    "        'regressor__alpha': [1e-3, 1e-2, 1e-1]\n",
    "       # 'regressor__degree': [2, 3, 4],\n",
    "       # 'regressor__C': [1e-2, 1e-1, 1, 1e1, 1e2]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(model, cv=3, n_jobs=-1, param_grid=params)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(grid.best_estimator_.named_steps['regressor'])\n",
    "    print('Done in {} s'.format(time() - st))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
